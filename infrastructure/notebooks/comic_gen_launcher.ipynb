{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AI Comic Book Generator - Colab Launcher\n",
                "\n",
                "This notebook runs the AI Comic Generator **completely FREE** using local Ollama models.\n",
                "**No API keys needed!** Everything runs on Colab's free GPU."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 1. Initial Setup (Run Once)\n",
                "# @markdown Installs Ollama, zstd, and clones the repository.\n",
                "REPO_URL = \"https://github.com/yogesh-dixit-dev/comic-generator.git\" # @param {type:\"string\"}\n",
                "BRANCH = \"master\" # @param {type:\"string\"}\n",
                "\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Install zstd (required by Ollama install script)\n",
                "print(\"üì¶ Installing dependencies (zstd)...\")\n",
                "os.system(\"apt-get update -qq && apt-get install -y -qq zstd\")\n",
                "\n",
                "# Install Ollama\n",
                "print(\"üì¶ Installing Ollama...\")\n",
                "os.system(\"curl -fsSL https://ollama.com/install.sh | sh\")\n",
                "\n",
                "# Start Ollama server in background\n",
                "print(\"üöÄ Starting Ollama server...\")\n",
                "os.system(\"nohup ollama serve > ollama.log 2>&1 &\")\n",
                "\n",
                "# Pull the models\n",
                "import time\n",
                "time.sleep(5) # Wait for server\n",
                "print(\"‚¨áÔ∏è Downloading Reasoning Model (Llama 3.1 8B - this may take 5-10 mins)...\")\n",
                "os.system(\"ollama pull llama3.1\")\n",
                "\n",
                "print(\"‚¨áÔ∏è Downloading Fast Model (Llama 3.2 3B)...\")\n",
                "os.system(\"ollama pull llama3.2\")\n",
                "\n",
                "# Clone or update repo\n",
                "if not os.path.exists(\"comic-gen\"):\n",
                "    os.system(f\"git clone -b {BRANCH} {REPO_URL} comic-gen\")\n",
                "\n",
                "os.chdir(\"/content/comic-gen\")\n",
                "os.system(\"pip install -q -r requirements.txt\")\n",
                "\n",
                "print(\"\\n‚úÖ Core Installation Complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 2. Update Code (Run after every fix!)\n",
                "# @markdown Pulls the latest changes from GitHub WITHOUT re-installing everything.\n",
                "import os\n",
                "if os.path.exists('/content/comic-gen'):\n",
                "    os.chdir('/content/comic-gen')\n",
                "    print(\"üîÑ Pulling latest code...\")\n",
                "    os.system(\"git fetch --all\")\n",
                "    os.system(\"git reset --hard origin/master\")\n",
                "    print(\"\\n‚úÖ Code Updated to Latest Version!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 2b. Pull Missing Models (Quick Fix)\n",
                "# @markdown Run this if you get a \"model not found\" error.\n",
                "import os\n",
                "os.system(\"ollama pull llama3.1\")\n",
                "os.system(\"ollama pull llama3.2\")\n",
                "print(\"\\n‚úÖ Models Ready!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 3. Configuration (Optional - Hugging Face Storage)\n",
                "import os\n",
                "from google.colab import userdata\n",
                "\n",
                "try:\n",
                "    os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
                "    print(\"‚úÖ Loaded HF token from Colab Secrets\")\n",
                "except:\n",
                "    print(\"‚ö†Ô∏è No HF_TOKEN in Colab Secrets. Output will stay local.\")\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 4. Progress Tracking Helper\n",
                "import subprocess\n",
                "import re\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "def run_pipeline_with_progress(command, phase_name):\n",
                "    print(f\"üöÄ Starting {phase_name} Phase...\")\n",
                "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
                "    \n",
                "    pbar = tqdm(total=100, desc=phase_name, unit=\"%\")\n",
                "    last_progress = 0\n",
                "    \n",
                "    for line in iter(process.stdout.readline, ''):\n",
                "        # Print regular logs but skip noisy progress markers for cleaner UI\n",
                "        if \"[PROGRESS]\" in line:\n",
                "            match = re.search(r\"\\[PROGRESS\\] (\\d+)%\", line)\n",
                "            if match:\n",
                "                progress = int(match.group(1))\n",
                "                pbar.update(progress - last_progress)\n",
                "                last_progress = progress\n",
                "        else:\n",
                "            print(line, end='')\n",
                "            \n",
                "    pbar.n = 100\n",
                "    pbar.refresh()\n",
                "    process.wait()\n",
                "    if process.returncode == 0:\n",
                "        print(f\"\\n‚úÖ {phase_name} complete!\")\n",
                "    else:\n",
                "        print(f\"\\n‚ùå {phase_name} failed with code {process.returncode}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 5. Phase 1: Knowledge & Visual Planning\n",
                "# @markdown Runs narrative scripting, character design, and panel planning.\n",
                "INPUT_FILE = \"story.txt\" # @param {type:\"string\"}\n",
                "OUTPUT_DIR = \"output\" # @param {type:\"string\"}\n",
                "USE_HF_STORAGE = False # @param {type:\"boolean\"}\n",
                "HF_REPO_ID = \"your-username/comic-dataset\" # @param {type:\"string\"}\n",
                "\n",
                "import os\n",
                "os.chdir('/content/comic-gen')\n",
                "storage_flag = f\"--storage hf --hf_repo '{HF_REPO_ID}'\" if USE_HF_STORAGE and os.environ.get('HF_TOKEN') else \"--storage local\"\n",
                "\n",
                "cmd = f\"python src/main.py --input '{INPUT_FILE}' --output '{OUTPUT_DIR}' --phase plan --colab {storage_flag}\"\n",
                "run_pipeline_with_progress(cmd, \"Planning\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 6. Phase 2: Isolated Image Generation\n",
                "# @markdown Loads the vision plans and draws high-quality images with full GPU dedicated to SDXL.\n",
                "INPUT_FILE = \"story.txt\" # @param {type:\"string\"}\n",
                "OUTPUT_DIR = \"output\" # @param {type:\"string\"}\n",
                "USE_HF_STORAGE = False # @param {type:\"boolean\"}\n",
                "HF_REPO_ID = \"your-username/comic-dataset\" # @param {type:\"string\"}\n",
                "\n",
                "import os\n",
                "os.chdir('/content/comic-gen')\n",
                "storage_flag = f\"--storage hf --hf_repo '{HF_REPO_ID}'\" if USE_HF_STORAGE and os.environ.get('HF_TOKEN') else \"--storage local\"\n",
                "\n",
                "cmd = f\"python src/main.py --input '{INPUT_FILE}' --output '{OUTPUT_DIR}' --phase draw --colab {storage_flag}\"\n",
                "run_pipeline_with_progress(cmd, \"Drawing\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 7. Download Output\n",
                "from google.colab import files\n",
                "import os\n",
                "\n",
                "if os.path.exists('output'):\n",
                "    os.system(\"zip -r comic_output.zip output\")\n",
                "    files.download('comic_output.zip')\n",
                "    print(\"‚úÖ Download started!\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è No output folder found. Did the pipeline run successfully?\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}