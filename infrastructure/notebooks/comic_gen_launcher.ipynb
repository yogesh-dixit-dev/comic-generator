{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AI Comic Book Generator - Colab Launcher\n",
                "\n",
                "This notebook runs the AI Comic Generator **completely FREE** using local Ollama models.\n",
                "**No API keys needed!** Everything runs on Colab's free GPU."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 1. Initial Setup (Run Once)\n",
                "# @markdown Installs Ollama, zstd, and clones the repository.\n",
                "REPO_URL = \"https://github.com/yogesh-dixit-dev/comic-generator.git\" # @param {type:\"string\"}\n",
                "BRANCH = \"master\" # @param {type:\"string\"}\n",
                "\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Install zstd (required by Ollama install script)\n",
                "print(\"üì¶ Installing dependencies (zstd)...\")\n",
                "!apt-get update -qq && apt-get install -y -qq zstd\n",
                "\n",
                "# Install Ollama\n",
                "print(\"üì¶ Installing Ollama...\")\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "\n",
                "# Start Ollama server in background\n",
                "print(\"üöÄ Starting Ollama server...\")\n",
                "!nohup ollama serve > ollama.log 2>&1 &\n",
                "\n",
                "# Pull the models\n",
                "import time\n",
                "time.sleep(5) # Wait for server\n",
                "print(\"‚¨áÔ∏è Downloading Reasoning Model (Llama 3.1 8B - this may take 5-10 mins)...\")\n",
                "!ollama pull llama3.1:8b\n",
                "\n",
                "print(\"‚¨áÔ∏è Downloading Fast Model (Llama 3.2 3B)...\")\n",
                "!ollama pull llama3.2:3b\n",
                "\n",
                "# Clone or update repo\n",
                "if not os.path.exists(\"comic-gen\"):\n",
                "    !git clone -b $BRANCH $REPO_URL comic-gen\n",
                "\n",
                "%cd /content/comic-gen\n",
                "!pip install -q -r requirements.txt\n",
                "\n",
                "print(\"\\n‚úÖ Core Installation Complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 2. Update Code (Run after every fix!)\n",
                "# @markdown Pulls the latest changes from GitHub WITHOUT re-installing everything.\n",
                "\n",
                "%cd /content/comic-gen\n",
                "print(\"üîÑ Pulling latest code...\")\n",
                "!git fetch --all\n",
                "!git reset --hard origin/master\n",
                "print(\"\\n‚úÖ Code Updated to Latest Version!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 3. Configuration (Optional - Hugging Face Storage)\n",
                "import os\n",
                "from google.colab import userdata\n",
                "\n",
                "try:\n",
                "    os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
                "    print(\"‚úÖ Loaded HF token from Colab Secrets\")\n",
                "except:\n",
                "    print(\"‚ö†Ô∏è No HF_TOKEN in Colab Secrets. Output will stay local.\")\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 4. Run Pipeline (Tiered Local Models - No API Calls!)\n",
                "INPUT_FILE = \"story.txt\" # @param {type:\"string\"}\n",
                "OUTPUT_DIR = \"output\" # @param {type:\"string\"}\n",
                "USE_HF_STORAGE = False # @param {type:\"boolean\"}\n",
                "HF_REPO_ID = \"your-username/comic-dataset\" # @param {type:\"string\"}\n",
                "\n",
                "import os\n",
                "os.chdir('/content/comic-gen')\n",
                "    \n",
                "print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
                "print(\"ü§ñ Using TIERED Local Models (Llama 3.1 8B + Llama 3.2 3B) - No API calls!\\n\")\n",
                "\n",
                "storage_flag = f\"--storage hf --hf_repo '{HF_REPO_ID}'\" if USE_HF_STORAGE and os.environ.get('HF_TOKEN') else \"--storage local\"\n",
                "\n",
                "!python src/main.py --input \"$INPUT_FILE\" \\\n",
                "                    --output \"$OUTPUT_DIR\" \\\n",
                "                    --reasoning_model \"ollama/llama3.1:8b\" \\\n",
                "                    --fast_model \"ollama/llama3.2:3b\" \\\n",
                "                    --colab {storage_flag}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 5. Download Output\n",
                "from google.colab import files\n",
                "import os\n",
                "\n",
                "if os.path.exists('output'):\n",
                "    !zip -r comic_output.zip output\n",
                "    files.download('comic_output.zip')\n",
                "    print(\"‚úÖ Download started!\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è No output folder found. Did the pipeline run successfully?\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}